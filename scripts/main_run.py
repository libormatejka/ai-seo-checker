#!/usr/bin/env python3
"""
Hlavn√≠ denn√≠ run - stahuje v≈°echny dotazy z Google Sheets
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# P≈ôidej cestu ke sd√≠len√Ωm funkc√≠m
sys.path.append(str(Path(__file__).parent))

from shared_functions import (
    init_google_sheets,
    load_brands,
    load_queries,
    process_queries_parallel,
    save_failed_queries,
    setup_logging,
    CONFIG
)

# Logging
logger = setup_logging("main_run")

def main():
    logger.info("=" * 60)
    logger.info("üöÄ MAIN DAILY RUN STARTED")
    logger.info("=" * 60)
    
    # Naƒçti credentials z environment
    perplexity_key = os.getenv("PERPLEXITY_KEY")
    gemini_key = os.getenv("GEMINI_KEY")
    
    if not perplexity_key or not gemini_key:
        logger.error("‚ùå Missing API keys in environment")
        sys.exit(1)
    
    # Inicializuj Sheets
    try:
        wb = init_google_sheets()
        logger.info("‚úÖ Google Sheets connected")
    except Exception as e:
        logger.error(f"‚ùå Failed to connect to Sheets: {e}")
        sys.exit(1)
    
    # Naƒçti brandy a dotazy
    try:
        brands = load_brands(wb)
        queries = load_queries(wb)
        
        logger.info(f"üìä Loaded {len(brands)} brands, {len(queries)} queries")
        
        if not queries:
            logger.warning("‚ö†Ô∏è  No queries to process")
            sys.exit(0)
    except Exception as e:
        logger.error(f"‚ùå Failed to load data: {e}")
        sys.exit(1)
    
    # Zpracuj v≈°echny dotazy
    start_time = datetime.now()
    
    try:
        results = process_queries_parallel(
            queries=queries,
            brands=brands,
            providers=CONFIG['active_providers'],
            max_workers=CONFIG['max_workers'],
            perplexity_key=perplexity_key,
            gemini_key=gemini_key
        )
    except Exception as e:
        logger.error(f"‚ùå Processing failed: {e}")
        sys.exit(1)
    
    # Ulo≈æ selhan√© dotazy do JSON
    failed_path = Path("data/failed_queries.json")
    failed_path.parent.mkdir(exist_ok=True)
    
    save_failed_queries(results['failed'], failed_path)
    
    # Report
    elapsed = (datetime.now() - start_time).total_seconds()
    
    logger.info("=" * 60)
    logger.info("‚úÖ MAIN RUN COMPLETED")
    logger.info(f"‚è±Ô∏è  Duration: {elapsed/60:.1f} minutes")
    logger.info(f"‚úÖ Successful: {results['successful']}")
    logger.info(f"‚ùå Failed: {results['failed_count']}")
    logger.info(f"üìä Success rate: {results['successful']/(results['successful']+results['failed_count'])*100:.1f}%")
    logger.info("=" * 60)
    
    # Exit s chybou pokud v√≠c ne≈æ 30% selhalo
    if results['successful'] + results['failed_count'] > 0:
        failure_rate = results['failed_count'] / (results['successful'] + results['failed_count'])
        if failure_rate > 0.3:
            logger.error(f"‚ö†Ô∏è  High failure rate: {failure_rate*100:.1f}%")
            sys.exit(1)

if __name__ == "__main__":
    main()
